%-*-coding: utf-8;-*-
\documentclass[italian,a4paper]{scrartcl}
\usepackage{amsmath,amssymb,amsthm,thmtools}
\usepackage{eucal,babel,a4}
\usepackage[dvipsnames]{xcolor}
\usepackage[nochapters]{classicthesis}
\usepackage[utf8]{inputenc}

\newcommand{\RR}{{\mathbb R}}
\newcommand{\C}{{\mathcal C}}
\newcommand{\eps}{\varepsilon}
\newcommand{\defeq}{=}
\renewcommand{\vec}{\mathbf}


\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$ }
\vcenter{\hbox{$#2#3$ }}\kern-.6\wd0}}
\def\dashint{\Xint-}

\declaretheoremstyle[
spaceabove=6pt, spacebelow=6pt,
headfont=\normalfont\itshape,
notefont=\mdseries, notebraces={(}{)},
bodyfont=\normalfont,
postheadspace=1em,
qed=,
shaded={rulecolor=pink!30,rulewidth=1pt,bgcolor=pink!10}
]{mystyle}

\declaretheorem[numberwithin=section,name=Teorema]{theorem}
\declaretheorem[sibling=theorem,name=Lemma]{lemma}
\declaretheorem[sibling=theorem,name=Definizione]{definition}
\declaretheorem[style=mystyle,sibling=theorem,name=Esercizio]{exercise}
\declaretheorem[style=mystyle,sibling=theorem,name=Esempio]{example}


\title{Formula dell'area\\per superfici regolari}
\author{E. Paolini}
\date{26 ottobre 2014}

\begin{document}
\maketitle

Nel seguito indicheremo con $\lvert E \rvert = \mathcal L^n(E)$ la
misura di Lebesgue di un insieme misurabile $E\subset \RR^n$. 

\section{Formula del cambio di variabili negli integrali multipli}

\begin{theorem}
Sia $L\colon \RR^n \to \RR^n$ una applicazione lineare. Allora per
ogni insieme misurabile $E\subset \RR^n$ si ha
\[
  \lvert L(E) \rvert = \lvert \det L \rvert \cdot \lvert E\rvert.
\]
\end{theorem}
\begin{proof}
Procederemo per casi: partendo dai casi più semplici e
utilizzando i casi precedenti, si arriverà alla fine al risultato generale.

\emph{Caso 1.} Mostriamo che il teorema vale se supponiamo che $L$ sia diagonale e
che $E$ sia un plurintervallo. Più precisamente $L(x_1,\dots x_n) =
(\lambda_1 x_1, \dots, \lambda_n x_n)$ e $E = [a_1,b_1) \times \dots
\times [a_n, b_n)$. 
In questo caso l'applicazione lineare manda il plurintervallo in un
altro plurintervallo, precisamente: 
\[
  L(E) = [\lambda_1 a_1, \lambda_1 b_1)\times \dots \times [\lambda_n a_n, \lambda_n b_n).
\]
Sappiamo però che la misura di un plurintervallo è il prodotto delle
lunghezze degli spigoli che lo compongono, quindi: 
\begin{align*}
|E| & = |b_1-a_1|\dots |b_n-a_n| \\
|L(E)| &= |\lambda_1 b_1 - \lambda_1 a_1|\dots |\lambda_n b_n - \lambda_n a_n| \\ 
    &= \lvert \lambda_1\rvert \dots \lvert \lambda_n\rvert \cdot
\lvert E\rvert 
     = \lvert \det L \rvert \cdot \lvert E \rvert. 
\end{align*}

\emph{Caso 2.} Il teorema vale se $L$ è diagonale ed $E$ è
misurabile. Per la definizione di misura esterna di Lebesgue esistono
degli insiemi $E_j\supset E$ che sono unione numerabile disgiunta di
plurintervalli e tali che $\lvert E \rvert = \lim \lvert
E_j\rvert$.
Ma allora $L(E)\subset L(E_j)$ quindi
\[
\lvert L(E)\rvert 
\le \lvert L(E_j)\rvert 
= \lvert \det L \rvert \cdot \lvert E_j \rvert 
\to \lvert \det L \rvert \cdot \lvert E \rvert.
\]
Se $\lvert \det L\rvert = 0$ abbiamo concluso. 
In caso contrario $L$ risulta essere invertibile e quindi si può
applicare lo stesso ragionamento alla mappa $L^{-1}$ ottenendo la
disuguaglianza opposta per l'insieme $F=L(E)$:
\[
 \lvert L^{-1}(F) \rvert \le \lvert \det L^{-1}\rvert \cdot \lvert F \rvert
\]
e, ricordando che $\det L^{-1} = 1/\det L$, $F=L(E)$ e $L^{-1}(F)=E$,
arriviamo alla conclusione voluta.

\emph{Caso 3.} Il teorema vale se $L$ è una \emph{matrice di
  permutazione}, ovvero se $L(x_1, \dots, x_n) = (x_{\sigma(1)},
\dots, x_{\sigma(n)})$ dove $\sigma\colon \{1,\dots,n\}\to\{1,\dots,
n\}$ è una qualunque permutazione.
Infatti osserviamo che $L$ siffatta manda ogni plurintervallo in un
plurintervallo in cui le lunghezze degli spigoli sono state
permutate tramite $\sigma$. Ma la misura di tale plurintervallo
rimane invariata.
Dunque $|L(E)|=|E|$ se $E$ è un plurintervallo. 
Con lo stesso ragionamento utilizzato nel caso 2, si estende il
risultato a qualunque insieme misurabile. Visto che in questo caso
$\det L = \pm 1$, abbiamo ottenuto quanto voluto.

\emph{Caso 4.}
Il teorema vale se $L$ è una applicazione del tipo:
\[
L \vec x = \vec x + \lambda x_j \vec e_i
\]
con $i\neq j$ indici fissati e $\lambda \in \RR$. 
In pratica la matrice che rappresenta $L$ è l'identità più un valore
$\lambda$ posizionato nella cella $i,j$ fuori dalla diagonale.
Chiaramente $\det L=1$ quindi anche in questo caso dobbiamo dimostrare
che la misura di $L(E)$ coincide con la misura di $E$. Il risultato si
ottiene mediante il teorema di Fubini (ovvero il principio di
Cavalieri), 
infatti affettando l'insieme $L(E)$ con i piani $x_i
= t$, osserviamo che la mappa $L$ ristretta a tali piani è una
traslazione in direzione $\vec e_j$ di ampiezza $\lambda t$:
$L\vec x = \vec x + \lambda t \vec e_j$. Dunque 
la misura $(n-1)$-dimensionale di ogni sezione è conservata e così la
misura $n$-dimensionale dell'intero insieme è conservata. 

\emph{Conclusione.}
Chiamiamo \emph{elementari} le matrici descritte nei
casi 3 e 4. Queste matrici elementari, se moltiplicate a sinistra per
una matrice $L$ compiono le operazioni elementari dell'algoritmo di
riduzione di Gauss: le matrici del caso 3 permutano le righe di $L$ e
le matrici del caso 4 sommano ad una riga il multiplo di un'altra
riga. Il metodo di riduzione di Gauss ci permette quindi di trovare 
matrici elementrari $S_1\dots S_N$ che, moltiplicate a
sinistra,
riducono la matrice
$L$ prima a scala e poi a diagonale:
\[
  S_1 \dots S_N L = D.
\]
Da un lato visto che il determinante di ogni $S_k$ è $\pm 1$,
otteniamo che $\det L = \pm \det D$. D'altro lato, per quanto riguarda
la misura dell'immagine di un insieme, visto che per quanto visto
sopra vale $\lvert S_k(E)\rvert = \lvert E \rvert$ si ha:
\[
\lvert L(E)\rvert = \lvert S_1 \dots S_N(L(E))\rvert = \lvert
D(E)\lvert = \lvert \det D \rvert\cdot \lvert E\rvert.
\]
Di conseguenza $\lvert L(E)\rvert = \lvert \det L\rvert \cdot \lvert E \rvert$. 
\end{proof}

\begin{theorem}[misura dell'immagine di una mappa regolare]
Sia $E\subset \RR^n$ un insieme aperto e limitato, e sia $\Phi\colon
\bar E \to \RR^n$ una mappa iniettiva di classe\footnote{Ci sarebbe da
discutere su cosa significa che una funzione è derivabile in un
punto del bordo del suo dominio. In tali punti, infatti, il
differenziale potrebbe non essere unico... e la continuità delle
derivate parziali potrebbe non essere sufficiente a garantire la
continuità della funzione. In alcuni testi si intende
che la funzione può essere estesa a tutto un aperto che contiene la
chiusura dell'insieme richiedendo che sia differenziabile su tale
aperto. In questo teorema è sufficiente che il differenziale esista
nei punti interni dell'insieme e che la funzione si possa estendere
con continuità sui punti del bordo del dominio.} $\mathcal C^1$.
Allora si ha
\[
 \lvert \Phi(\bar E) \rvert = \int_{\bar E} \lvert \det D\Phi(\vec x)\rvert\,
 d\vec x.
\]
\end{theorem}
\begin{proof}[Idea della dimostrazione.]
\emph{Passo 1.}
Sia $Q_\rho(\vec x)$ il cubo centrato nel punto $\vec x$
di lato $\rho$ e con gli spigoli paralleli agli assi coordinati
di $\RR^n$.

Dimostriamo innanzitutto che per ogni punto $\vec{x_0}\in E$
si ha
\[
  \lim_{\rho\to 0} \frac{\lvert\Phi(Q_\rho(\vec {x_0}))\rvert}{\rho^n} 
  = \lvert \det D\Phi(\vec{x_0})\rvert.
\]
In effetti visto che $\Phi$ è differenziabile in $\vec {x_0}$ 
sappiamo che scelta la mappa lineare $L\vec x = D\Phi(\vec {x_0})(\vec
x-\vec {x_0})$
si ha
\[
\lim_{\vec x\to \vec{x_0}} \frac{\lvert \Phi(\vec x) - \Phi(\vec{x_0})
  - L(\vec x-\vec{x_0}) \rvert}{|\vec x-\vec {x_0}|} = 0.
\]
Per semplicità supponiamo che $\vec{x_0}=\vec 0$ e
$\Phi(\vec{x_0})=\vec 0$ (a meno di
traslazioni lo possiamo fare) e poniamo $Q_\rho \defeq Q_\rho(\vec 0)$.
Per ogni $\eps>0$ esiste quindi un $\delta>0$ tale che per ogni
$\rho<\delta$ 
e per ogni $x\in B_\rho$ si ha:
\[
\lvert \Phi(\vec x) - L\vec x \rvert \le \frac{\eps}{\sqrt n}|\vec x|.
\]
Osservando che $|\vec x| \le \sqrt n \rho$ (visto che $\vec x \in Q_\rho$) 
si ottiene dunque
che ogni punto dell'insieme $\Phi(Q_\rho)$ si trova ad una
distanza inferiore di $\eps \rho$ da un qualche punto dell'insieme
$L(Q_\rho)$. Diciamo che $\Phi(Q_\rho)$ è contenuto 
nell'intorno di raggio $\eps\rho$ dell'insieme $L(Q_\rho)$.
Senza entrare nei dettagli\footnote{Si tratta di stimare il volume del
contorno di ampiezza $\epsilon \rho$ di $L(Q_\rho)$ ricoprendolo con cubi di lato
dell'ordine di $\eps\rho$. 
Per motivi dimensional la misura del contorno
potrà essere stimata (a meno di costanti) con $\eps$ volte il volume
dell'intero insieme 
$L(Q_\rho)$ e quindi con $C\eps\rho^n$}, questo ci
garantisce che per una qualche costante $C$ si abbia
\[
  \lvert \Phi(Q_\rho) \rvert \le \lvert L(Q_\rho)\rvert + C \eps \rho^n
\]
e dal teorema precedente ricordiamo che $\lvert L(Q_\rho)\rvert
=\lvert \rho L (Q_1)\rvert = \rho^n\lvert \det L\rvert$. Dunque
\[
\frac{\lvert \Phi(Q_\rho) \rvert}{\rho^n} 
\le \lvert \det L\rvert + C\eps.
\]

Con un ragionamento simile (erodendo l'insieme $L(Q_\rho)$ di una
quantità $\eps\rho$) si potrà ottenere una stima ``dal basso'' del tipo:
\[
\frac{\lvert \Phi(Q_\rho)\rvert}{\rho^n} \ge \lvert \det L \rvert - c \eps.
\]
Mettendo assieme le due disuguaglianze, facendo prima tendere $\rho\to
0$ e poi $\eps\to 0$ si ottiene come voluto
\[
\lim_{\rho \to 0} \frac{\lvert \Phi(Q_\rho) \rvert}{\rho^n} 
= \lvert \det L \rvert = \lvert \det D\Phi(\vec {x_0})\rvert
\]

\emph{Passo 2.}
Poniamo
\[
 \theta(\vec x) \defeq 
\lim_{\rho \to 0} \frac{\lvert
   \Phi(Q_\rho(\vec x)) \rvert}{\rho^n}
=
\lim_{\rho \to 0} \frac{\lvert
   \Phi(Q_\rho(\vec x)) \rvert}{\lvert Q_\rho\rvert}.
\]
Nel passo precedente abbiamo mostrato che $\theta(\vec x)=\lvert
\det D\Phi(\vec x)\rvert$.
Dalla definizione di limite, 
per ogni punto $\vec x\in E$ e per ogni $\eps>0$ è possibile trovare $r=r(\vec x)$ tale
che per ogni $\rho<r$ si abbia
\[
-\eps \le \theta(\vec x) - \frac{\lvert \Phi(Q_\rho(\vec x))\rvert}{\lvert Q_\rho\rvert}\le \eps.
\]
Senza entrare in complicati dettagli\footnote{Si faccia riferimento al
teorema di ricoprimento di Vitali}, diciamo che fissato $\eps>0$ è possibile trovare
un insieme numerabile di cubi digiunti $Q_j\subset E$ centrati nei punti
$\vec x_j$ che ricoprono quasi ogni punto di $E$ (cioè la misura
dell'unione dei cubi è uguale alla misura di $E$) e tali che:
\[
-\eps \le \theta(\vec x_j) - \frac{\lvert \Phi(Q_j)\rvert}{\lvert Q_j\rvert}\le\eps.
\]

Consideriamo allora la funzione semplice
$$
\theta_\eps(\vec x) = \sum_j \theta(\vec x_j) \mathbb 1_{Q_j}(\vec x)
$$
e osserviamo che si ha $\theta_\eps(\vec x) = \theta(\vec {x_j})$ dove
$\vec {x_j}$ 
è il centro del cubo $Q_j$ che contiene $\vec x$. Possiamo senz'altro supporre
che per $\eps \to 0$ anche il lato dei cubi tenda a zero cosicché si
avrà $\theta_\eps(\vec x)\to \theta(\vec x) = \lvert \det D\Phi(\vec
x)\rvert$ per ogni $\vec x \in E$.

Inoltre si ha
\begin{align*}
\lvert \Phi(E) \rvert
= \sum_j \lvert \Phi(Q_j)\rvert
= \sum_j \theta(\vec x_j)\lvert Q_j \rvert  \pm \eps \lvert Q_j \rvert
= \int_E \theta_\eps(\vec x)\, d\vec x \pm \eps \lvert E\rvert
\end{align*}
dove con $A\pm B$ intendiamo un valore compreso tra $A-B$ e $A+B$. 

Al tendere di $\eps \to 0$, abbiamo già osservato che
$\theta_\eps(\vec x) \to \theta(\vec x)$, inoltre per ogni
$\eps>0$ e per ogni $\vec x\in E$ si ha $\lvert \theta_\eps(\vec
x)\rvert \le M$ con $M=\max_{\vec x \in \bar E} \theta(\vec
x)$. Abbiamo infatti supposto che $D\Phi$ sia continua e quindi
$\theta = \lvert \det D\Phi\rvert$ è pure continua ed essendo $\bar E$ 
compatto tale funzione ammette massimo per il teorema di Weierstra\ss.
Dunque si applica il teorema di convergenza dominata e per $\eps\to 0$
otteniamo 
\[
\lvert \Phi(E) \rvert = \int_E \theta(\vec x)\, d\vec x.
\]

Osserviamo infine che essendo $E$ misurabile si ha $\lvert \partial
E\rvert = 0$ e quindi l'integrale fatto su $E$ 
o su $\bar E$ ci dà lo stesso risultato.
\end{proof}

\begin{theorem}[formula del cambio di variabili]
Nelle stesse ipotesi del teorema precedente, sia $f\colon \Phi(\bar E) \to
\RR$ una funzione integrabile. Allora si ha
\[
\int_{\Phi(\bar E)} f(\vec y) \, d\vec y 
=\int_{\bar E} f(\Phi(\vec x)) \lvert \det D\Phi(\vec x)\rvert\,
d\vec x.
\]
\end{theorem}

\begin{proof}[Idea della dimostrazione.]
Se $f$ è una funzione semplice, costante sugli insiemi $F_j=\Phi(E_j)$
\[
  f(\vec y) = \sum_j \alpha_j \mathbb 1_{\Phi(E_j)}(\vec y)
\]
ci si può ricondurre al teorema precedente:
\begin{align*}
  \int_{\Phi(\bar E)} f(\vec y) \, d\vec y
  &= \int_{\Phi(\bar E)} \sum_j \alpha_j \mathbb 1_{F_j}(\vec y)\, d\vec y
  = \sum_j \alpha_j \lvert\Phi(E_j)\rvert  \\
  &= \sum_j \alpha_j \int_{E_j} \lvert \det D\Phi(\vec x)\rvert\,
  d\vec x\\
  &= \int_{\bar E} \sum_j \alpha_j \mathbb 1_{E_j}(\vec x)\lvert\det D\Phi(\vec x)\rvert\,
  d\vec x
  = \int_{\bar E} g(\vec x)\, d\vec x
\end{align*}
avendo posto
\[
  g(\vec x) = \sum_j \alpha_j \mathbb 1_{E_j}(\vec x)\lvert\det D\Phi(\vec x)\rvert.
\]

Se ora $f$ è integrabile non negativa, per definizione sappiamo che esistono $f_k$
funzioni semplici che convergono decrescendo a $f$ e tali che
$\int f_k \to \int f$. Le corrispondenti funzioni $g_k$ risultano
anch'esse essere funzioni che convergono decrescendo alla funzione
$g(\vec x) = f(\Phi(\vec x))\lvert \det D\Phi(\vec
x)\rvert$. Dunque per il teorema di Beppo Levi il loro integrale
converge all'integrale di $g$ e quindi si ottiene il risultato voluto.

Se $f$ ha segno qualunque, possiamo applicare il passo precedente alla
parte positiva e alla parte negativa di $f$, ottenendo quindi il
risultato generale.
\end{proof}

\section{Formula dell'area}
\begin{theorem}
Sia $L\colon \RR^k \to \RR^n$ con $k\le n$ una applicazione lineare.
Allora per ogni insieme misurabile $E\subset \RR^k$ si ha
\[
  \lvert L(E)\rvert = \sqrt{\det L^t L} \cdot \lvert E \rvert
\]
dove con $\lvert L(E)\rvert$ intendiamo la misura di
Lebesgue $\mathcal L^k(R(L(E)))$ con $R$ una qualunque isometria che
manda $\mathrm Im L$ in $\RR^k$.
\end{theorem}
\begin{proof}
Sia $R\colon \RR^n \to \RR^k$ una applicazione lineare che ristretta a $\mathrm{Im} L$ risulti
essere una isometria. Questo significa che, per ogni $\vec v \in
\RR^k$ si ha
\[
  \lvert R L \vec v\rvert = \lvert L \vec v\rvert
\]
ovvero, elevando al quadrato,
\[
  \vec v^t L^t R^t R L \vec v = \vec v^t L^t L \vec v
\]
e portando tutto al primo membro:
\[
 \vec v^t (L^t R^t R L - L^t L) v = 0.
\]
Ma se $M$ è una matrice simmetrica e $\vec v^tM\vec v=0$ per
ogni $\vec v$, per il principio di identità delle forme
quadratiche\footnote{Basta osservare che 
\[
(x-y)^t M (x-y) = x^t M x + y^t M y - 2 x^t M y
\]
da cui
\[
x^t M y = \frac{x^tMx + y^tMy - (x-y)^t M (x-y)}{2}.
\]
Dunque se $v^t M v = 0$ per ogni $v$, il membro di destra è sempre
nullo e quindi anche $x^t M y$ è nullo per ogni $x$ e $y$. 
Dunque $M$ è la matrice nulla.
} si ottiene che $M=0$, dunque otteniamo
\[
  L^t R^t R L = L^t L.
\]

Osserviamo ora che
\[
  \lvert R(L(E))\rvert = \lvert \det{RL} \rvert \cdot \lvert E \rvert
\]
e, per quanto osservato poco sopra,
\[
 \lvert \det RL \rvert = \sqrt{ \det L^t R^t R L }
 = \sqrt{ \det L^t L}.
\]
\end{proof}

Il teorema precedente giustifica la seguente definizione.

\begin{definition}[area di una superficie]
Una funzione iniettiva $\Phi\colon E \subset \RR^k \to \RR^n$ si dice essere una
\emph{$k$-superficie parametrizzata}.
Se $\Phi$ è di classe $\mathcal C^1$,
definiamo l'area della superficie parametrizzata da $\Phi$ con la
seguente formula:
\[
\mathcal A(\Phi(E)) \defeq \int_E J(D\Phi(\vec x))\, d\vec x
\]
dove 
\[
  J(L) = \sqrt{\det L^t L}
\]
si chiama \emph{jacobiano} o \emph{elemento d'area} associato alla
mappa lineare $L$.

Se $f\colon\Omega\subset \RR^n \to \RR$ è una funzione definita su un insieme $\Omega\supset \Phi(E)$
e se $f\circ \Phi$ è una funzione integrabile su $E$, definiamo
l'integrale di superficie:
\[
  \int_{\Phi(E)} f(\vec y)\, d\sigma(\vec y)
 = \int_E f(\Phi(\vec x)) J(D\Phi(\vec x))\, d\vec x.
\]
La notazione $d\sigma(\vec y)$ sta a rappresentare l'elemento
d'area nell'integrazione rispetto alla variabile $\vec
y$. Formalmente si ha quindi $d\sigma(\vec y) = J(D\Phi(\vec
x))\, d\vec x$ quando $\vec y$ varia sulla superficie
$\Phi(E)$. 

\end{definition}
\begin{example}[area della superficie sferica]
La superficie di una sfera di raggio $R$ può essere descritta tramite
due coordinate $\theta,\phi$ che rappresentano la \emph{longitudine} e
la \emph{latitudine}. La relazione tra le coordinate cartesiane
$x,y,z$ e le coordinate sferiche $\rho,\theta,\phi$ è:
\[
\begin{cases}
  x = \rho \cos \phi \cos \theta\\
  y = \rho \cos \phi \sin \theta\\
  z = \rho \sin \phi.
\end{cases}
\]

Se $\rho=R$ è fissato, otteniamo una mappa $\Phi$ definita sul
rettangolo $E=\{(\theta,\phi)\colon \theta \in [-\pi,\pi],
\phi\in[-\pi/2, \pi/2]\}$
\[
\Phi(\theta,\phi) = R (\cos \phi \cos \theta,
\cos \phi \sin \theta,
\sin \phi).
\]

La matrice jacobiana di $\Phi$ è 
\[
D\Phi = 
\begin{pmatrix}
\displaystyle
\frac{\partial \Phi}{\partial \theta} &
\displaystyle
\frac{\partial \Phi}{\partial \phi}
\end{pmatrix}
=
\begin{matrix}
-R\cos \phi\sin \theta & -R \sin \phi\cos \theta\\
R\cos \phi \cos \theta & -R \sin \phi \sin \theta \\
0 & R\cos \phi
\end{matrix}
\]
e quindi
\[
D\Phi^t D\Phi = 
R\begin{pmatrix}
R^2\cos^2 \phi & 0 \\
0 & R^2
\end{pmatrix}
\]
da cui
\[
J(D\Phi) = \sqrt{\det D\Phi^t D\Phi} = R^2\cos \phi.
\]

Possiamo quindi calcolare l'area della sfera $S=\Phi(E)$:
\begin{align*}
\mathcal A(S) &= \int_E R^2 \cos \phi \,d \theta\, d \phi
=\int_{-pi}^\pi d \theta \int_{-\frac \pi 2}^{\frac \pi 2} d\phi R^2
\cos\phi
\\
&= 2\pi R^2\big[\sin \phi\big]_{-\frac \pi 2}^{\frac \pi 2} 
= 4 \pi R^2.
\end{align*}
\end{example}

\begin{example}[baricentro di una semisfera]
Si consideri la semisfera $S$ consistente dei punti $\vec x\in
\RR^3$ che soddisfano le relazioni: $\lvert \vec x\rvert = R$, $x_3\ge 0$. Vogliamo
calcolare
\[
  \int_S x_3\, d\sigma(\vec x).
\]
Parametrizziamo la sfera in coordinate\dots sferiche $\theta, \phi$:
\[
\begin{cases}
  x_1 = R \cos \phi \cos \theta\\
  x_2 = R \cos \phi \sin \theta\\
  x_3 = R \sin \phi
\end{cases}
\]
per cui posto $\Phi(\theta,\phi) = R ( \cos\phi\cos \theta, \cos
\phi\sin \theta, \sin \phi)$ si ha $S=\Phi(E)$ dove $E$ è il
rettangolo $E=\{(\theta,\phi)\colon -\pi \le \theta \le \pi, 0 \le
\phi \le \pi/2\}$.

Dunque
\begin{align*}
  \int_S x_3\, d\sigma(\vec x) 
  &= \int_E R \sin \phi R^2 \cos \phi\, d\theta d\phi
  = R^3 \int_{-\pi}^\pi d \theta \int_0^{\frac \pi 2} d \phi \sin \phi
  \cos \phi
\\
  &= 2\pi R^3[\frac 1 2 \sin^2 \phi]_0^{\frac \pi 2}
  = \pi R^3.
\end{align*}

Sapendo che l'area della semisfera è $\mathcal A(S) = 2\pi R^2$, si
trova la coordinata $\bar x_3$ del baricentro:
\[
\bar x_3 = \frac{\int_S x_3\, d \sigma}{\mathcal A(S)} = \frac{\pi
  R^3}{4 \pi R^2} = \frac 1 4 R.
\]
\end{example}

\begin{theorem}[formula di Cauchy-Binet]
Sia $L$ una matrice $n \times k$ con $k\le n$. Allora
\[
  \det L^t L = \sum_{\text{$M$ minore $k\times k$ di L}} \det(M)^2.
\]
La somma viene fatta al variare di $M$ tra tutte le sottomatrici di
$L$ che si possono ottenere eliminando $n-k$ righe a scelta.
\end{theorem}
\begin{proof}[Non dimostrazione.]
La dimostrazione può essere fatta per verifica diretta per $k \le n
\le 3$. La dimostrazione del caso generale è piuttosto complessa, e
richiede di espandere il determinante come somma su tutte le
permutazioni di $k$ elementi.
\end{proof}

\begin{example}[area del grafico]
Sia $f \colon \Omega\subset \RR^n \to \RR$ una funzione di classe
$\mathcal C^1$. La superficie che rappresenta il grafico di $f$ può
essere parametrizzata tramite $\Phi\colon \Omega\subset \RR^n \to
\RR^n\times \RR$ definita da
\[
  \Phi(\vec x) = (\vec x, f(\vec x)).
\]
Allora si ha
\[
  D\Phi(\vec x) = \begin{pmatrix}
  \mathrm Id\\
  Df(\vec x)
\end{pmatrix}.
\]
Applicando la formula di Cauchy-Binet
si ottiene:
\[
  \det(D\Phi^t D\Phi) = \sqrt{1+\lvert Df\rvert^2}
\]
e dunque:
\[
\mathcal A(\Phi) = \int_\Omega \sqrt{1+\lvert Df(\vec x)\rvert^2}\,
d \vec x.
\]
\end{example}

\section{Il prodotto vettoriale}

Nel caso di superfici $\Phi\colon E \subset \RR^2 \to \RR^3$ possiamo
rappresentare lo jacobiano della trasformazione, e altre proprietà
geometriche della superficie, mediante il prodotto vettoriale.

Se $\vec u, \vec v, \vec w$ sono vettori di $\RR^3$,
definiamo il loro \emph{prodotto triplo} come:
\[
  det (\vec u, \vec v, \vec w)
\]
cioè consideriamo il determinante della matrice le cui colonne sono i
tre vettori dati. Osserviamo che questo può essere fatto solo perché
abbiamo $n=3$ vettori in $\RR^n$.

Il prodotto tripolo ha le proprietà del determinante: è multi-lineare
(cioè lineare in ognuno dei tre vettori in ingresso) e alternante
(cioè scambiando due vettori il prodotto triplo cambia segno).

Se fissiamo due dei tre vettori $\vec u, \vec v$ e lasciamo
variare il terzo $\vec w$ otteniamo una funzione lineare $\RR^3 \to
\RR$:
\[
 \vec w \mapsto \det(\vec u, \vec v, \vec w).
\]
Ogni applicazione lineare può essere rapresentata tramite prodotto
scalare con un vettore di $\RR^3$. Definiamo quindi il \emph{prodotto
  vettoriale} tra $\vec u$ e $\vec v$ che indichiamo con
$\vec u \wedge \vec v$ (notazione alternativa: $\vec u \times
\vec v$) il vettore che soddisfa la seguente relazione:
\[
\det (\vec u, \vec v, \vec w) = (\vec u \wedge \vec v) \cdot \vec w.
\]

Dalle proprietà di antisimmetria del determinante, osserviamo che:
\[
(\vec u \wedge \vec v)\cdot \vec u = 0, \qquad
(\vec u \wedge \vec v)\cdot \vec v = 0
\]
che significa che il vettore $\vec u \wedge \vec v$ è perpendicolare sia a
$\vec u$ che a $\vec v$ cioè è perpendicolare al piano individuato dai
due vettori.

Osserviamo inoltre che il prodotto triplo è invariante per movimenti
rigidi, cioè se applichiamo una stessa rotazione a tutti e tre i
vettori, il prodotto triplo non cambia (in quanto stiamo moltiplicando la
matrice $(\vec u,\vec v,\vec w)$ per una matrice con determinante $1$).

In particolare se $\vec u, \vec v, \vec w$ sono tra loro ortogonali li
possiamo ruotare in modo che le 3 direzioni risultino parallele agli
assi coordinati. La matrice diventa quindi diagonale e il valore assoluto
del determinante risulta essere il prodotto dei moduli dei tre vettori.
In particolare se
$\vec u$ e $\vec v$ sono ortogonali si ha $\lvert \vec u \wedge \vec
v\rvert = \lvert \vec u \rvert \cdot \lvert \vec v \rvert$ in quanto
risulta $\lvert \vec u \wedge \vec v\rvert^2 = \lvert\det (\vec u, \vec v,
\vec u \wedge \vec v)\rvert = \lvert \vec u \rvert \cdot \lvert \vec v
\rvert \cdot \lvert \vec u \wedge \vec v \rvert$.

Definito l'angolo $\alpha$ in base alla formula
\[
  (\vec u, \vec v) = \lvert \vec u \rvert\, \lvert \vec v \rvert \cos \alpha,
\]
e posto 
\[
 \lambda \defeq \frac{\lvert\vec v\rvert \cos \alpha}{\lvert \vec u\rvert}
  = \frac{(\vec u,\vec v)}{\lvert \vec u \rvert^2}
\]
visto che (per antisimmetria) $\vec u \wedge \vec u = 0$, 
si ha:
\[
\vec u \wedge \vec v = \vec u \wedge (\vec v - \lambda\vec u)
\]
ed essendo $\vec u$ ortogonale a $\vec v - \lambda \vec u$ (verificare
facendo il prodotto scalare!), si
ottiene
\[
\lvert \vec u \wedge \vec v\rvert = \lvert \vec u \rvert \, \lvert
\vec v -\lambda \vec u\rvert
\]
ma
\begin{align*}
\lvert \vec v-\lambda \vec u\rvert^2
&= \lvert v\rvert^2 + \lambda^2 \lvert \vec u \rvert^2 - 2 \lambda
(\vec u, \vec v) 
= \lvert v \rvert^2 + \lvert v\rvert^2 \cos^2 \alpha - 2 \lvert \vec
v\rvert^2 \cos^2 \alpha \\
&=\lvert v\rvert^2 \sin^2 \alpha
\end{align*}
e in conclusione
\[
 \lvert \vec u \wedge \vec v \rvert = \lvert \vec u\rvert \, \lvert
 \vec v \rvert \lvert\, \sin\alpha\rvert.
\]

Per calcolare le coordinate (componenti) di un prodotto vettore
osserviamo che si ha
\begin{equation}
\label{eq:componenti_prodotto_vettore}
\begin{aligned}
  \vec u \wedge \vec w &= \sum_{i=1}^3 (\vec u\wedge \vec w,\vec{e_i}) \vec{e_i}
  = \sum_{i=1}^3 \det(\vec u, \vec v, \vec{e_i}) \vec{e_i}\\
  &=
    \det\begin{pmatrix}u_2 & v_2 \\ u_3 & v_3\end{pmatrix} \vec{e_1}
  - \det\begin{pmatrix}u_1 & v_1 \\ u_3 & v_3\end{pmatrix} \vec{e_2}
  + \det\begin{pmatrix}u_1 & v_1 \\ u_2 & v_2\end{pmatrix} \vec{e_3}
  \end{aligned}
\end{equation}
che porta alla formula \emph{mnemonica}:
\[
\text{``\mbox{}}\vec u \wedge \vec w = \det\begin{pmatrix}
  u_1 & v_1 & \vec{e_1} \\
  u_2 & v_2 & \vec{e_2} \\
  u_3 & v_3 & \vec{e_3}
\end{pmatrix}\text{''}
\]
giustificata dal fatto che la linearità del determinante sull'ultima
colonna ci dà, 
formalmente, la \eqref{eq:componenti_prodotto_vettore}.

Osserviamo infine che se $L=(\vec u,\vec v)$ è la matrice $3\times 2$ le cui due
colonne sono i vettori $\vec u$ e $\vec v$, si ha
\begin{equation}\label{eq:jacobiano_e_prodotto_vettore}
  \lvert \vec u\wedge \vec v \rvert = J(L).
\end{equation}
Questa può essere considerata una applicazione del Teorema
Cauchy-Binet enunciato più sopra. Infatti abbiamo visto in 
\eqref{eq:componenti_prodotto_vettore} che le
componenti del vettore $\vec u \wedge \vec v$ sono proprio (a meno del
segno) i deteminanti dei tre minori $2\times 2$.

Senza usare il Teorema di Cauchy-Binet (che non abbiamo dimostrato)
si può dimostrare \eqref{eq:jacobiano_e_prodotto_vettore} come segue.
Scegliamo il vettore $\vec w = \vec u \wedge \vec v$ 
si ha 
\begin{align*}
\lvert \vec u\wedge \vec v\rvert^2 \lvert \vec w \rvert ^2 
&=
(\vec u \wedge \vec v, \vec w)^2
=\big(\det(\vec u, \vec v, \vec w)\big)^2 
=
\det \left((\vec u,\vec v,\vec w)^t (\vec u,\vec v,\vec w)\right) 
\\
&=
\det
\begin{pmatrix}
  L & \begin{array}{c}0\\0\end{array} \\
  0 \  0 & \lvert \vec w\rvert^2
\end{pmatrix}
= \det (L^t L) \lvert \vec w\rvert^2
= (J(L))^2 \lvert \vec w \rvert^2.
\end{align*}

Se $\Phi\colon E\subset \RR^2 \to \RR^3$ è una parametrizzazione
$\mathcal C^1$ di una superificie, indicando con $u,v$ le variabili in
$\RR^2$ e con $x,y,z$ le variabili in $\RR^3$ cosicché la superficie
corrisponde all'equazione:
\[
 (x,y,z) = \Phi(u,v)
\]
la matrice jacobiana di $\Phi$ può essere scritta nei seguenti modi:
\[
D\Phi = 
\begin{pmatrix}
\frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} \medskip\\
\frac{\partial y}{\partial u} & \frac{\partial y}{\partial v} \medskip\\
\frac{\partial z}{\partial u} & \frac{\partial z}{\partial v}
\end{pmatrix}
=
\begin{pmatrix}
\displaystyle
\frac{\partial \Phi}{\partial u} &
\displaystyle
\frac{\partial \Phi}{\partial v}
\end{pmatrix}.
\]

Gli integrali di superficie possono quindi essere scritti nel seguente
modo:
\[
\int_{\Phi(E)} f\, d\sigma
=\int_E f(\Phi(u,v))\, 
\left\vert \frac{\partial \Phi}{\partial u} \wedge
\frac{\partial \Phi}{\partial v}\right\vert\, 
du\, dv
\]
dove l'espressione formale
\[
d\sigma = \left\vert \frac{\partial \Phi}{\partial u} \wedge
\frac{\partial \Phi}{\partial v}\right\vert\, 
du\, dv
\]
rappresenta quindi l'elemento \emph{infinitesimo} di area sulla
superficie $\Phi(E)$.

Cerchiamo ora di dare un significato \emph{geometrico} alla direzione 
del vettore
$\xi
= \frac{\partial \Phi}{\partial u} \wedge
\frac{\partial \Phi}{\partial v}$.
Osserviamo innanzitutto che il rango della matrice jacobiana $D\Phi$ è
massimo (cioè 2) se e solo se $\xi \neq 0$. Infatti il rango è zero se
e solo se i due vettori colonna di $D \Phi$ sono uno il multiplo
dell'altro: ma in tal caso il loro prodotto vettore risulta essere
nullo. Se invece i due vettori hanno direzioni diverse, il prodotto
vettore risulta essere diverso da zero.

Se il rango della matrice $D\Phi$ è massimo,
potremo definire il piano tangente alla superficie $\Phi(E)$ nel punto
$\Phi(u,v)$ come
l'immagine della applicazione lineare associata alla matrice jacobiana
$D\Phi(u,v)$ ovvero come lo spazio generato dai due vettori colonna.
Dunque dalle proprietà del prodotto vettore osserviamo che il vettore
$\xi$ è ortogonale al piano tangente e può quindi essere
utilizzato per identificare la direzione \emph{normale} alla superficie.

\section*{Registro modifiche}
\begin{itemize}
\item[2014-10-17] Prima stesura.
\item[2014-10-26] Aggiunto prodotto vettore e altri aggiustamenti.
\end{itemize}
\end{document}
